#!/usr/bin/env python3

# exploreFit.py 				Eric Anderson (3/16)
# A basic fit of generated data, as a sanity check.  We should be able to
# fit pretty well to the generated data, as it is, for the most part, just
# generated by linear interpolation.  We'll separate the data into train,test
# and validation sets using our data splitter helper.

# This file uses several methods for fitting and is intended merely as a proof of concept.


import visualization as v
import speedModel as sm
import numpy as np 
import pandas as pd
from sklearn.linear_model import LinearRegression as LR
from sklearn.neighbors import KNeighborsRegressor as KNN
from sklearn.ensemble import RandomForestRegressor as RFR
import sklearn.mixture as Mix

def main():
  np.random.seed(0)       #For repeatability

  #Read in the training data
  print('Reading data from hardcoded file')
  with open('genTrain.csv','r') as f:
    x = pd.read_csv(f)

  #Get a validation set
  print('Creating Validation and Training sets')
  vFrac = 0.2
  print('Splitting off a validation set of size ' + str(vFrac))
  val = x.sample(frac = vFrac)
  x = x[~x.index.isin(val.index)]    #Get the complement

  #Reset the indices
  x = x.reset_index(drop=True)
  val = val.reset_index(drop=True)

  #Break into x and y
  # y = x.loc[:,'boatSpeed']
  # yVal = val.loc[:,'boatSpeed']
  # x.drop(['boatSpeed'],axis=1,inplace=True); 
  # val.drop(['boatSpeed'],axis=1,inplace=True); 

  # v.vizRawData(x.loc[:20,:])
  v.vizRawData(x.loc[:1500,:])

  print('X and Validation Shapes:')
  print(x.shape)
  print(val.shape)
  # print(y.shape)
  # print(yVal.shape)
  # print(x.head())
  # print(val.head())
  # print(y.head())
  # print(yVal.head())

  print('--------------------\n      FITS\n--------------------\n')


  ############################
  #   LINEAR REGRESSION      #
  ############################
  '''
  print('Fitting Data with Linear Regression\n...\n')  
  lr = LR().fit(x,y)

  print('Fitting Training Data')
  yhat = lr.predict(x)
  mse = ((yhat-y)**2).mean()
  print('Training Data MSE: ' + str(mse) + '\n')

  print('Fitting Validation Data')
  yhat = lr.predict(val)
  mse = ((yhat-yVal)**2).mean()
  print('Validation Data MSE: ' + str(mse) + '\n')
  '''

  ############################
  #         KNN              #
  ############################
  '''
  n = 5
  print('Fitting Data with KNN Regression (' + str(n) + ' neighbors)\n...\n')
  knn = KNN(n_neighbors=n).fit(x,y)

  print('Fitting Training Data')
  yhat = knn.predict(x)
  mse = ((yhat-y)**2).mean()
  print('Training Data MSE: ' + str(mse) + '\n')

  print('Fitting Validation Data')
  yhat = knn.predict(val)
  mse = ((yhat-yVal)**2).mean()
  print('Validation Data MSE: ' + str(mse) + '\n')
  '''

  ############################
  #     KNN Controller       #
  ############################
  '''
  # n = 1000
  n = 300

  #Write my own fit, as I need to have access to the actual neighbors in question:
  #Weighted average of points, using weight like c*speed/d (with appropriate scaling) or speed/exp(d)
  #so we weight close points over fast points (that probably are just for higher windspeeds)
  #only really want to get avg for main,jib (don't care about bs, probably inaccurate anyways)
  #X is the fitted set, xPred is the set to predict, n_neighbors is the number of neighbors to use.
  def myPred(x,xPred,n_neighbors,printMax=False):
    # print('in myPred(), x has null?: ' + str(x.isnull().any().any()))
    ds,inds = knn.kneighbors(xPred,n_neighbors=n_neighbors)
    print('Maximum distance point used is : ' + str(ds.max())) if printMax else None
    out=pd.DataFrame(columns=['mainOut','jibOut'])
    for d,ind,i in zip(ds,inds,range(ds.shape[0])):
      # print(i)
      # print(d)
      # print(x.shape)
      # print(ind)
      # for i in ind:
      #   print(i in x.index.values)
      # print(x.loc[ind,'boatSpeed'].head())
      # print('\n')
      w = 10**(x.loc[ind,'boatSpeed'])/(d+1)                 #My weight function, not complete yet
      out.loc[i,'mainOut'] = ((x.loc[ind,'main'] * w).sum())/w.sum()
      out.loc[i,'jibOut'] = ((x.loc[ind,'jib'] * w).sum())/w.sum()
    
    out.index=xPred.index   #Make indices correspond
    return out
  
  #Wraps the KNN prediction in a nice API
  #Refs external vars x,n
  def knnController(windSpeed,windDir):
    ret = myPred(x,pd.DataFrame([[windSpeed,windDir]], columns=['windSpeed','windDir']),n)
    return (ret.iloc[0,0],ret.iloc[0,1])

  def myDist(x,y):
    #2 degress off course = 10 knots windspeed difference
    # print('x0: ' + str(x[0]))
    # print('x1: ' + str(x[1]))
    return (((x[0]-y[0])**2)/100 + ((x[1]-y[1])**2)/4)**0.5


  print('Fitting Data with KNN Regression (' + str(n) + ' neighbors)\n...\n')
  knn = KNN(n_neighbors=5,metric='pyfunc',func=myDist)

  # print(x.loc[:,['windSpeed','windDir']].shape)
  knn.fit(x.loc[:,['windSpeed','windDir']],x.loc[:,['main','jib','boatSpeed']])

  v.vizControlStrategy(knnController)

  # print('Fitting Training Data')
  # out = myPred(x,x.loc[:,['windSpeed','windDir']],n) 
  # #Calc MSE
  # errs = []
  # for w,sail in zip(x.index, out.index):
  #   mySpeed = sm.resultantSpeed(x.loc[w,'windSpeed'],x.loc[w,'windDir'],out.loc[sail,'mainOut'],out.loc[sail,'jibOut'])
  #   errs.append(mySpeed-x.loc[w,'boatSpeed'])
  # mse= (np.array(errs)**2).mean()
  # print('Training Data MSE: ' + str(mse) + '\n')

  if(input('Fit to Validation data? [Y/n]:') == 'Y'):
    print('Fitting Validation Data')
    out = myPred(x,val.loc[:,['windSpeed','windDir']],n,printMax=True)
    #Calc MSE
    errs = []
    for w,sail in zip(x.index, out.index):
      mySpeed = sm.resultantSpeed(x.loc[w,'windSpeed'],x.loc[w,'windDir'],out.loc[sail,'mainOut'],out.loc[sail,'jibOut'])
      errs.append(mySpeed-x.loc[w,'boatSpeed'])
    mse= (np.array(errs)**2).mean()
    print('Validation Data MSE: ' + str(mse) + '\n')
  '''

  ############################
  #      RANDOM FOREST       #
  ############################
  '''
  f = 30
  print('Fitting Data with Random Forest (Forest size of : ' + str(f) + ')\n...\n')
  rf = RFR(n_estimators=f, verbose=2, oob_score=True).fit(x,y)

  print('Fitting Training Data')
  yhat = rf.predict(x)
  mse = ((yhat-y)**2).mean()
  print('Training Data MSE: ' + str(mse) + '\n')

  print('Fitting Validation Data')
  yhat = rf.predict(val)
  mse = ((yhat-yVal)**2).mean()
  print('Validation Data MSE: ' + str(mse) + '\n')
  '''

  ############################
  # RANDOM FOREST CONTROLLER #
  ############################
  '''
  #TODO: maybe sample the sail space given windspeed and winddirection, then choose the best point? Degree accuracy is only 90*90 = 1800 points per query

  f = 20
  print('Fitting Data with Random Forest (Forest size of : ' + str(f) + ')\n...\n')
  rf = RFR(n_estimators=f, verbose=2, oob_score=True).fit(x.loc[:,x.columns.difference(['boatSpeed'])],x.loc[:,'boatSpeed'])

  # print('Fitting Training Data')
  # yhat = rf.predict(x.loc[:,x.columns.difference(['boatSpeed'])])
  # mse = ((yhat-x.loc[:,'boatSpeed'])**2).mean()
  # print('Training Data MSE: ' + str(mse) + '\n')

  # print('Fitting Validation Data')
  # yhat = rf.predict(val.loc[:,val.columns.difference(['boatSpeed'])])
  # mse = ((yhat-val.loc[:,'boatSpeed'])**2).mean()
  # print('Validation Data MSE: ' + str(mse) + '\n')

  def forestControl(windSpeed,windDir):
    query = pd.DataFrame(columns = x.columns.difference(['boatSpeed'])) #Empty dataframe with correct columns
    for m in range(19):       #Check every combination of angles (5 deg resolution)
      for j in range(19):
        query.loc[m*19+j,:] = {'windSpeed':windSpeed,'windDir':windDir,'main':m*5,'jib':j*5}
    pred = pd.DataFrame(rf.predict(query))
    ind = pred.idxmax()[0]
    # print((query.loc[ind,'main'],query.loc[ind,'jib']))
    return (query.loc[ind,'main'],query.loc[ind,'jib'])

  v.vizControlStrategy(forestControl)
  
  '''


  ############################
  #        DPGMM             #
  ############################
  '''
  n = 10
  print('Fitting Data with DPGMM (' +str(n) + ' components maximum)\n...\n')
  dpgmm = Mix.DPGMM(n_components=n, covariance_type='diag',verbose=0).fit(x,y )  #Can change verbosity but it's VERY verbose

  print('Fitting Training Data')
  yhat = dpgmm.predict(x)
  print(yhat[:10])
  ##FIXME: output from predict is just what gaussian it belongs to...

  print('Fitting Validation Data')
  yhat = dpgmm.predict(val)
  #mse = ((yhat-yVal)**2).mean()
  #print('Validation Data MSE: ' + str(mse) + '\n')
  '''

  #TODO: Test data here, eventually?


if __name__ == "__main__":
  main()